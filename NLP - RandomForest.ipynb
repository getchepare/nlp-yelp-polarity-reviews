{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base packages\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Import ML packages\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read train/test datasets\n",
    "Create a function to read train and test datasets with follow actions:\n",
    "- Have a look at readme.txt to get more information about the datasets\n",
    "- Columns should be renamed to 'rate' and 'text'\n",
    "- Take a random sample of 5000 records for training and test datasets\n",
    "- Positive labels should be mapped to 0 (instead of 2 in the initial dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_format_dataset(dataset_path):\n",
    "    \n",
    "    return()\n",
    "\n",
    "train_dataset_path = 'path_to_train_data'\n",
    "test_dataset_path = 'path_to_test_data'\n",
    "train_data = read_format_dataset(train_dataset_path)\n",
    "test_data = read_format_dataset(test_dataset_path)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training pipeline\n",
    "Our pipeline will use:\n",
    "- TFIDF to vectorize our text\n",
    "- RandomForest on top of these features\n",
    "\n",
    "You should first build this sklearn pipeline and use RandomizedSearchCV to get the best parameters for your pipeline. As our training dataset is small, you would probably increase the number of cross validations. Use accuracy as target metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline definition\n",
    "tfidf = ...\n",
    "\n",
    "rfc = ...\n",
    "\n",
    "pipe = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = {...}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(...)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on test dataset\n",
    "Compute the accuracy for our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rfc = ...\n",
    "y_pred = ...\n",
    "acc = ...\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}